\subsection{Requirements Specification and Analysis}

Software requirements specifications are usually stated in informal, imprecise
and ambiguous natural language, making analyzing them a challenging task.
The success of a system does not solely depend on its functional requirements,
but also significantly relies on adherence to non-functional requirements.
The primary focus of requirements analysis is generally towards the
identification and specification of \FRs. \NFRs are usually identified and
specified in later development stages, which can increase the risks of problems
during the development lifecycle. \NFRs may not be mentioned explicitly in a
formal specification requirements documents, even though they exist for all
systems in freeform documents such as interview notes or meeting minutes. All
types of requirements are analysed differently, and as such, it is useful to
separate them. This distinction helps in managing changes in requirements as
well as in precisely incorporating them in the development of the system. Manual
requirement division into \FRs and \NFRs is difficult and time-consuming.
Machine learning can be useful in supporting analysts in the error-prone task of
manually discovering and classifying requirements, having in mind easing further
analyses tasks.

\subsubsection{Identifying Non-Functional Requirements}
\tahira{Non-functional requirements may not be explicitly mentioned in a formal
specification requirements documents even though they exist for all
systems~\cite{Slankas:2013}. Moreover, freeform documents like interview notes,
meeting minutes and scattered requirements specifications include non-functional
requirements which need to be detected and classified. \ML can be
useful to support analysts in the error-prone task of manually discovering and
classifying \NFR. Automatic detection can be used to quickly and effectively
identifying \NFR in large and complex documents \cite{Cleland-Huang2007}}
This is a classification problem, as from a set of requirements we want to
decide whether or not requirements are \NFRs. 

In a study by Slankas \etal~\cite{Slankas:2013}, the authors automatically
identify and classify sentences in natural language coming from user agreements,
install manuals, regulations, requirements specifications and user manuals into 14
different \NFR categories, among which \emph{Access Control}, \emph{Audit},
\emph{Availability} or \emph{Legal}.
\tahira{\emph{Access Control}, \emph{Audit}, \emph{Availability},  and \emph{Legal} etc.
\emph{Look and Feel}, \emph{Maintenance}, \emph{Operational}, \emph{Privacy},
\emph{Recoverability}, \emph{Performance and Scalability}, \emph{Reliability},
\emph{Security} and \emph{Usability}.}
The authors' two-step process is as follows: 1) parsing natural language; 2)
classifying sentences into categories with the k-nearest neighbor algorithm.
This led the authors to finding 20 keywords for each category of \NFR which are
then used as features for their classifier.
They subsequently trained the \NFR classifier with a wide variety of open and
closed source EHRs (Electronic Health Record), various industry standards (HL7, CCHIT)
and governmental regulations.

\tahira{Cleland-Huang \etal~\cite{Cleland-Huang2007} explored a similar approach and
used the k-nearest neighbor classifier for grouping \NFR e.g.
\emph{availability}, \emph{look-and-feel}, \emph{legal}, \emph{maintainability},
\emph{operational}, \emph{performance}, \emph{scalability}, \emph{security}, and
\emph{usability}}
Cleland-Huang \etal~\cite{Cleland-Huang2007} explored a similar approach and
used the k-nearest neighbor classifier for grouping \NFRs e.g.
\emph{availability}, \emph{look-and-feel} or \emph{legal}. For training their
classifier, the authors used 15 requirement specifications developed as term
projects by master students at DePaul University.
\subsubsection{Identifying Functional Requirements}
\tahira{Software requirements specifications are usually stated in informal,
imprecise and ambiguous natural language, thus analyzing them is a challenging
task. However, for satisfying the specifications of a product analyzing
functional requirements is a vital task.Automatically extract structured
information of functional requirements from Software Requirements Specifications
and grouping them into different categories is a \ML classification
task\cite{7949577}.}This is a classification problem as from a set of
requirements we want to decide whether or not requirements are \FRs.
\tahira{Wang \etal~\cite{7949577} applied a combination of \ML, natural
language processing, and semantic analysis to automatically extract functional
requirements and classify them into ten different cases: Agentive (The main
participant of activities), \emph{action} (the main functional operation),
 \emph{objective} (the objects affected by the Action), \emph{agent mode} (the
 modifier or property of the Agentive), \emph{objmod} (the modifier or property
 of the Agentive), \emph{locational} (the location or
 destination of an Action), \emph{temporal} (the occurrence time or frequency of
 an Action), \emph{manner} (the way or tool by which an Action is performed),
 \emph{goal} (the purpose to be achieved through the Action) and
 \emph{constraint} (the conditions or constraints of the \emph{action}). Their
 framework employed techniques of semantic role labelling (which assigns a 
role  label  for  each  word  in  the  sentence) and machine learning and has four steps: corpus construction, NLP
 preprocessing, feature extraction and EFRF (Extended Functional Requirements
 Frame) functional cases extraction. \emph{Bring to the preprocessing section: For NLP processing they did
 tokenization, lemmatization, part-of-speech tagging (POS tagging) and
 dependency parsing.}}

Wang \etal~\cite{7949577} applied a combination of \ML, \NLP and semantic
analysis to automatically extract functional requirements and classify them into
different types, such as action, objective, goal, temporal or constraints. Their
framework employed techniques of semantic role labelling (which assigns a role
label for each word in the sentence).
The authors trained a variant of Recurrent Neural Network using a E-commerce
requirements dataset and tested it on the requirements from the automotive
industry. Their approach stemmed from analysing the linguistic characterization
of software requirement specifications. The framework consists of 10 \FR
types and allows capturing semantic information in natural language. \tahira{The authors have
shown that their model trained on an e-commerce requirements dataset can be used
to classify functional requirements and extract semantic information from the
requirements of automaker systems.}
\subsubsection{Distinguishing Functional from Non functional Requirements}

\tahira{The success of a system does not solely depend on its functional requirements.
Like for functional requirements, it also significantly depends on the adherence
to non-functional requirements. The primary focus of requirements analysis is
generally towards the identification and specification of \FR. \NFR are usually
identified and specified in later development stages which can increase the
risks of problems during the development lifecycle. \FR tend to be more
straightforward e.g. store and retrieve data when a user performs some specific action\levi{transaction?}. On the
other side, \NFR are complicated and challenging to implement for example making the
design to meet the \NFR or design test cases for \NFR\levi{unclear}.
Different types of requirements are analyzed differently, and as such, it is
useful to separate them. This distinction helps in managing changes in
requirements as well as in precisely incorporating them in the development of
the system. Manually dividing requirements in \FR and \NFR is difficult and
time-consuming. \ML can be used for reducing the effort and
categorizing the requirements based on the text segment analysis\emph{what is
this?}This is \ML classification task: give the set of requirements and
identifying its category.}This
is a classification problem as from a set of requirements we want to decide
whether or not requirements belong to a certain class. 

Lu \etal~\cite{Lu:2017} automatically classifies text from user reviews for
(app) stores into \FRs or \NFRs. The authors further classify \NFRs
into four categories: reliability, usability, portability, and
performance. The approach used a supervised algorithm called
\emph{bagging}.\levi{is bagging an algorithm?} \tahira{ yes it is from ensemble
learning training the classifier.}\levi{I think there is a conflict with the
same word in the preprocessing text.}The sentences were augmented by several
similar words to the user reviews in the training set. The authors
used 6696 raw user reviews from iBooks and 4400 raw user reviews from WhatsApp.

Deoxadez \etal~\cite{Deocadez:2017} use semi-supervised classification
techniques for automated classification of \FR and \NFR from user reviews
originally from the app store. This study deals with two problems: 1) minimizing
the annotation effort for labelling a big dataset of user reviews, and 2)
classification of requirements into \FR and \NFR. The proposed solution to the
first problem used a semi-supervised self-labelling algorithm. Self-labelling
algorithms require small datasets to produce results that are comparable to supervised techniques.
Features were obtained by applying standard pre-processing and the \BOW
algorithm. The \emph{Naive Bayes} classification algorithm was used for the
second problem. The authors used reviews coming from the top-ranked 40 paid and
free apps.

Kurtanovic \etal~\cite {Kurtanovic:2017} analysed software requirements
documents written in natural language in order to classify them as \FRs, \NFRs
and subcategories of \NFRs. The authors used the \SVM algorithm for the
classification. The dataset was imbalanced in terms of \FRs and
\NFRs. For avoiding this problem user comments on software products coming
from Amazon were integrated into the main dataset. The study used data from
the open source tera PROMISE repository that consists of 625 labeled natural
language requirements (255 \FR [40.8\%] and 370 \NFR[59.2\%]).

Abad \etal~\cite{Abad:2017} targeted two similar problems: the first one is the
classification of comments on apps into \FRs and \NFRs, and the second the
classification of \NFRs into categories.
After pre-processing they increased the weight of influential words in the
dataset using feature co-occurrence and regular expressions. The authors then
used the decision tree (\DT) J.48 algorithm for the classification. Additionally,
Binarized Naive Bayes (\BNB) was used for sub-classification of \NFRs. The study
showed that the treatment after the pre-processing approach positively
influenced the classification. The approach used reviews from the 40 top-ranked
paid and free apps.

Garzoli \cite {Garzoli:2013} proposed a system for the analysis of requirements
that allowed identifying software functionalities within large collections of
requirements written in natural language. It classified the large dataset into
five types: \FRs, \NFRs, \emph{design and construction constraints},
\emph{operator requirements} and \emph{performance requirements}.  The goal of
the study was to devise a general architecture for large-scale and
adaptive requirement analysis. It used \BOW together with text mining techniques
for inferring lexical and grammatical feature for information retrieval. \SVM
was used for the classification of requirements. The dataset contained 4,727
annotated requirements, related to three different scenarios and was taken
from a naval combat management system.

Wieloch \etal presented in~\cite{Wieloch:2013} Trace by Classification, an \ML
approach in which a classifier is trained to identify and classify requirements
and/or other kinds of software artefacts which occur relatively frequently
across different projects. In their research the authors call this process
generating trace links for software artefacts in their research.
The first step in the approach is to eliminate common stop words. Then, in the
training phase the authors identify a set of indicator terms for each \NFR
category. The classifier is then trained by the set of identified weighted
indicator terms which is then used to classify additional artefacts into
functional or non-functional requirements (e.g. look-and-feel, performance,
security, etc). A probability value represents the certainty that the new
requirement belongs to a certain artefact type, computed as a function of the
occurrence of indicator terms of that type in the requirement.

\subsubsection{Requirement Prioritization}
Complex software systems generally have thousands of requirements with multiple
stakeholders and customers. Each one of them has their own set of requirements
and opinions and wants their requirements implementation accordingly. However,
factors such as budget or different opinions among stakeholders often make
implementing all the requirements a complicated task. Therefore, it is
important to make a proper decision for prioritizing requirements considering
all the factors that are important for the success of the project. Different
models exist in the literature for prioritizing software requirements, among
which analytical hierarchical process (AHP) \cite{saaty2008}, Goal oriented
\cite{VanLamsweerde:2001} or the cost value approach \cite{Karlsson:1997}. In
these techniques, human input is very important. Qaddoura \etal
\cite{R.Qaddoura} reviewed  prioritization techniques and also shed light on the
contribution of \ML to the topic. \ML can be used for automated analysis of
these large set of software requirements prioritization, as well as in helping
to improve existing techniques.

Dhingra \etal  \cite{S.Dhingra} predicted from a portfolio of prioritization
methods the most appropriate technique for software requirement prioritization
process. The input from the user was taken as characteristic values (detect
consistency, maintain information, not available, or both) for different attributes. These attributes list included
consistency, traceability, priority basis, rigorous/systematic, distributed
stakeholder, cognitive aspects, and human experience. The output was the most
appropriate requirement prioritization method e.g. AGORA, AHP etc. The
framework proposed has three phases; training phase, fuzzing inference
process, and testing phase. The drawback of fuzzy approach was the wrong prediction for
boundary values, which was resolved by adopting decision trees. \DT learned
from datasets and predicted the most suitable prioritization technique. Out of
45 test samples, the framework classified 43 instances accurately.

Avesani \etal presented in \cite{PAvesani} a study that dealt with the
scalability problems that arise in managing the prioritization of a large number
of requirements when using the AHP technique. The existing solution to
scalability issues used heuristics to decide when the pairwise elicitation
process should be stopped. The proposed framework outperformed AHP by giving an
accurate approximation of the final ranking while restricting the elicitation
effort. It used a rank-based learning algorithm and produced a ranking of all
requirements. The input for the learning algorithm were a finite set
of requirements, the ranking criteria, initial user preferences and a density
function.

A similar study was performed in \cite{7320432} by the same group
\cite{PAvesani} for identifying decision-making issues related to the
management of risks in Open Source Software adoption in medium and large
organizations. A semi-automated system was proposed that used case-based
ranking classification algorithm. The input was priority elicitation of goals by
the decision maker and a risk goal ranking function (predefined ranking criteria
ordering the goal). As output, it ranked the final risk-based
goals.

\input{text/analysis_security}

