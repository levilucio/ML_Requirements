\subsection{Requirements Specification and Analysis}

Software requirements specifications are usually stated in informal, imprecise and ambiguous natural language, thus analyzing them is a challenging task. 
The success of a system does not solely depend on its functional requirements.
Like for functional requirements, it also significantly depends on the adherence
to non-functional requirements. The primary focus of requirements analysis is
generally towards the identification and specification of FRs. NFRs are usually
identified and specified in later development stages which can increase the
risks of problems during the development lifecycle. Non-functional requirements may not be explicitly mentioned in a formal
specification requirements documents even though they exist for all
systems~\cite{Slankas:2013}in freeform documents like interview notes,
meeting minutes.
All types of requirements are analyzed differently, and as such, it is
useful to separate them. This distinction helps in managing changes in
requirements as well as in precisely incorporating them in the development of
the system. Manual requirement division into FRs, NFRs, and  FRs and NFRs is difficult and
time-consuming. 
Machine learning can be
useful to support analysts in the error-prone task of manually discovering and
classifying them which will help to ease further analysis in further processing to analyse. Automatic detection can be used to quickly and effectively
identifying NFRs in large and complex documents.

\subsubsection{Identifying Non-Functional Requirements}
\tahira{Non-functional requirements may not be explicitly mentioned in a formal
specification requirements documents even though they exist for all
systems~\cite{Slankas:2013}. Moreover, freeform documents like interview notes,
meeting minutes and scattered requirements specifications include non-functional
requirements which need to be detected and classified. Machine learning can be
useful to support analysts in the error-prone task of manually discovering and
classifying NFRs. Automatic detection can be used to quickly and effectively
identifying NFRs in large and complex documents \cite{Cleland-Huang2007}}This
is a classification problem as from a set of requirements we want to decide
whether or not requirements belong to NFRs . 

	In a study by Slankas \etal~\cite{Slankas:2013} the authors automatically
identify and classify sentences in natural language from use agreements, install
manuals, regulations, requests for proposals\emph{proposals of what?},
requirements specifications, and user manuals into 14 different NFRs categories such as 
\emph{Access Control}, \emph{Audit}, \emph{Availability},  and \emph{Legal} etc.
\tahira{\emph{Access Control}, \emph{Audit}, \emph{Availability},  and \emph{Legal} etc.
\emph{Look and Feel}, \emph{Maintenance}, \emph{Operational}, \emph{Privacy},
\emph{Recoverability}, \emph{Performance and Scalability}, \emph{Reliability},
\emph{Security} and \emph{Usability}.}
Their two-step process: 1) parse natural language and turn sentences into graphs
2) classify sentences into categories with k-nearest neighbor algorithm led them
into finding 20 keywords for each category of NFRs as features for their
classifier. They trained the NFR classifier
with a wide variety of open and closed source EHRs (Electronic Health Record),
various industry standards (HL7, CCHIT), governmental regulations, and other
document sources exist to elicit documentation.

\tahira{Cleland-Huang \etal~\cite{Cleland-Huang2007} explored a similar approach and
used the k-nearest neighbor classifier for grouping non-functional requirements e.g.
\emph{availability}, \emph{look-and-feel}, \emph{legal}, \emph{maintainability},
\emph{operational}, \emph{performance}, \emph{scalability}, \emph{security}, and
\emph{usability}}
 	Cleland-Huang \etal~\cite{Cleland-Huang2007} explored a similar approach and
used the k-nearest neighbor classifier for grouping non-functional requirements e.g.
\emph{availability}, \emph{look-and-feel}, \emph{legal}. For training their classifier they used 15 requirements specifications developed as term projects by master students at DePaul University.

\subsubsection{Identifying Functional Requirements}

\tahira{Software requirements specifications are usually stated in informal, imprecise and ambiguous natural language, thus analyzing them is a challenging task. However, for satisfying the specifications of a product analyzing functional requirements is a vital task.Automatically extract structured information of functional requirements from Software Requirements Specifications and grouping them into different categories is a machine learning classification task\cite{7949577}.}This
is a classification problem as from a set of requirements we want to decide
whether or not requirements belong to a FRs. 
\tahira{Wang \etal~\cite{7949577} applied a combination of machine learning, natural
language processing, and semantic analysis to automatically extract functional
requirements and classify them into ten different cases: Agentive (The main
participant of activities), \emph{action} (the main functional operation),
 \emph{objective} (the objects affected by the Action), \emph{agent mode} (the
 modifier or property of the Agentive), \emph{objmod} (the modifier or property
 of the Agentive), \emph{locational} (the location or
 destination of an Action), \emph{temporal} (the occurrence time or frequency of
 an Action), \emph{manner} (the way or tool by which an Action is performed),
 \emph{goal} (the purpose to be achieved through the Action) and
 \emph{constraint} (the conditions or constraints of the \emph{action}). Their
 framework employed techniques of semantic role labeling (which assigns a 
role  label  for  each  word  in  the  sentence) and machine learning and has four steps: corpus construction, NLP
 preprocessing, feature extraction and EFRF (Extended Functional Requirements
 Frame) functional cases extraction. \emph{Bring to the preprocessing section: For NLP processing they did
 tokenization, lemmatization, part-of-speech tagging (POS tagging) and
 dependency parsing.}}

	Wang \etal~\cite{7949577} applied a combination of machine learning, natural
language processing, and semantic analysis to automatically extract functional
requirements and classify them into ten different cases e.g. action, objective, goal, temporal, and constraints etc. Their
 framework employed techniques of semantic role labeling (which assigns a 
role  label  for  each  word  in  the  sentence) and
 machine learning and has four steps: corpus construction, NLP
 preprocessing, feature extraction and EFRF (Extended Functional Requirements
 Frame) functional cases extraction.
 The authors trained their bi-directional LSTM-CRF network,
 a variant of Recurrent Neural Networks architecture model, with an E-commerce
 requirements dataset and tested it on requirements of automaker systems. They
 proposed EFRF through analyzing the linguistic characterization of
 software requirement specifications. EFRF consists of the 10 FRs types mentioned
 above and allows capturing the semantic information in the natural language
 functional requirements. \tahira{The authors have shown that their
 model trained on an E-commerce requirements dataset can be used to classify functional requirements and extract
 semantic information from the requirements of automaker systems.}\\
\subsubsection{Distinguishing Functional from Non functional Requirements}

\tahira{The success of a system does not solely depend on its functional requirements.
Like for functional requirements, it also significantly depends on the adherence
to non-functional requirements. The primary focus of requirements analysis is
generally towards the identification and specification of FRs. NFRs are usually
identified and specified in later development stages which can increase the
risks of problems during the development lifecycle. FRs tend to be more
straightforward e.g. store and retrieve data when a user performs some specific action\levi{transaction?}. On the
other side, NFRs are complicated and challenging to implement for example making the
design to meet the NFRs or design test cases for NFRs\levi{unclear}.
Different types of requirements are analyzed differently, and as such, it is
useful to separate them. This distinction helps in managing changes in
requirements as well as in precisely incorporating them in the development of
the system. Manually dividing requirements in FRs and NFRs is difficult and
time-consuming. Machine learning can be used for reducing the effort and
categorizing the requirements based on the text segment analysis\emph{what is
this?}This is ML classification task: give the set of requirements and
identifying its category.}This
is a classification problem as from a set of requirements we want to decide
whether or not requirements belong to a certain class. 

 Lu \etal~ \cite{Lu:2017} automatically classify the text from user
reviews for (app) stores into FR, NFR, and others. The authors further classify
NFRs into four categories including reliability, usability, portability, and
performance. The approach uses a supervised machine learning algorithm
\emph{bagging}\levi{is bagging an algorithm?} \tahira{ yes it is from ensemble learning training the classifier.}
The text trimming used standard pre-processing steps. Also,  the sentences are
augmented by several most similar words to the user reviews in the training set
and showed that augmented user reviews can lead to better classification
results.\levi{unclear} The machine learning algorithm Bagging is more suitable
for NFRs classification from user reviews than Na√Øve Bayes and J48\levi{is this
conclusion because they tested with multiple algorithms or because it is better
than the SOA, in which case this should be mentioned in the table} \tahira{ they tried two classifier Naive Bayes and J.48 and results showed comparison of these two }. The authors
used 6696 raw user reviews from iBooks and 4400 raw user reviews from WhatsApp
as datasets.

	Deoxadez \etal~\cite{Deocadez:2017} used semi-supervised classification
techniques for automated classification of FRs and NFRs from user reviews from
the app store. This study dealt with two problems: 1) minimizing the annotation
effort for labeling the big dataset of user reviews, and 2) classification of
FRs and NFRs. The proposed solution to the first problem used
the semi-supervised self-labeling algorithm. Self-labeling algorithms required a
small amount of dataset to get comparable results as supervised techniques. Features were obtained
by applying the standard pre-processing and BoW algorithm. For user reviews classification \emph{Naive Bayes}
algorithm was selected, because of its general high-performance results in classification
problems. It used reviews of top 40 paid and free apps from ten
different categories.

	Kutranvoic \etal ~ \cite {Kurtanovic:2017} performed automated analysis on
software requirement documents written in natural language \levi{which kind?} and classify them into FRs,
NFRs and subcategories of NFRs. The basic pre-processing steps were applied on requirements before applying the ML algorithm. It used a supervised support vector machine (SVM) algorithm for classification.\levi{make sure we introduce the acronym before}. Some NFRs were ignored because of their minor presence in the documents. Also, the dataset was imbalanced that means it was not equally distributed. For avoiding data imbalance problem additional dataset i.e. user comments\levi{what is this?}
from Amazon was integrated into the main dataset. The basic pre-processing steps were applied on requirements before applying the ML algorithm. The study used data from open source tera PROMISE repository that consists of 625 labeled natural language requirements (255 FRs
[40.8\%] and 370 NFRs [59.2\%]).

	Abad \etal ~ \cite{Abad:2017} targeted two similar problems: the first one is the classification of FR and NFR and the second classification of NFR into categories.
 It first performed pre-processing for text trimming. Afterward, increased the weight of influential words in the
dataset using feature co-occurrence and regular
expression. It learnt J.48 decision tree (DT) for classification of FRs and NFRs. It used Binarized Naive Bayes (BNB) for sub-classification of NFRs. BNB outperformed among other algorithms such as clustering, k-means, and hybrid clustering and k-means. 
The study showed that the text pre-processing approaches positively influenced on classification. It improved FRs and NFRs
 classification accuracy from 89.92\% to 95.04\%. It used reviews of top 40 paid and free apps from ten
different categories.

	Garzoli \cite {Garzoli:2013} proposed a system for requirement analysis that allowed to identify software functionalities within large collections of requirements written in natural language for requirement analysis. It classified the large dataset into five types:
FRs, NFRs, \emph{design and construction constraints}, \emph{operator
requirements} and \emph{performance requirements}.  The goal of the study was to come up with a general
architecture for large-scale and adaptive requirement analysis. It used BoW with text mining techniques for lexical and grammatical feature for information retrieval and SVM\levi{is this ML?} model for classification of requirements. The learning classifiers contained 4,727 annotated requirements, related
to three different scenarios. The dataset was taken from
the combat management system of a Naval Combat System. The learning classifiers contained 4,727 annotated requirements, related
to three different scenarios\levi{what does the
dataset consist of?}

	Wieloch \etal~\cite{Wieloch:2013} introduced methods that enhance the accuracy
of tracing (classifying) requirements which occurred frequently across multiple
projects and/or domains. In the paper, they presented Trace by Classification
(TBC), a machine learning approach in which a classifier is trained to identify
and classify requirements and/or other kinds of software artifacts which occur
relatively frequently across different projects (they call this process
generating trace links for software artifacts in their research). \levi{Trivial
preprocessing step put in preprocessing section:
The first step in their approach was preprocessing to eliminate common stop
words.} Then the training phase identified a set of indicator
terms\levi{features?} for each NFR category and the classifier trained by the
set of identified weighted indicator terms that can be used for the last step which is to classify additional
artifacts into functional and non-functional (e.g.
look-and-feel, performance, security, etc). A probability value represented 
a possibility that the new requirement belonged to a certain artifact type computed as a function of the occurrence of indicator terms of that type in the requirement.\levi{shouldn't this go to the verification/traceability section?} \tahira{Parisa added this paper and according to her it just contained tracability and by tracability they mean classification}
\levi{shouldn't this go to the verification/traceability section?} \tahira{Parisa added this paper and according to her it just contained tracability and by tracability they mean classification}

\subsubsection{Requirement Prioritization}
Complex software system generally has thousands of requirements with multiple
stakeholders and customers. Each one of them has their own set of requirements
and opinions and wants their requirements implementation accordingly. However,
several factors make implementation process of all the requirements infeasible
and hard. For example project resources, time, budget, and different opinion among
stakeholders etc. effect project implementation. Therefore, it
is important to make a proper decision for prioritizing requirements considering
all the factors for the success of the project. Different models exist in the
literature for prioritization of software requirements such as analytical
hierarchical process (AHP) \cite{saaty2008}, Goal oriented
\cite{VanLamsweerde:2001}, cost value approach \cite{Karlsson:1997} etc.In these
techniques, human input is majorly involved. Qaddoura \etal \cite{RQaddoura}
reviewed the prioritization techniques and also shed light on the ML
contribution. ML can be used for automated analysis of these large set of
software requirements prioritization, and it can also help to improve the existing techniques.\\

	Dhingra \etal  \cite{S.Dhingra} predicted the most appropriate technique for
software requirement prioritization process. The input from the user was taken as characteristic values (detect consistency, maintain information, not available, or both) for different attributes. These attributes list included consistency,
traceability, priority basis, rigorous/systematic, distributed stakeholder,
cognitive aspects, and human experience.\levi{what is the characteristic value?} The output was the
most appropriate requirement prioritization method e.g. AGORA, AHP etc. Fuzzy interface technique was
used for prediction of prioritization method based on certain rules. The
proposed system framework had three phases; training phase, fuzzing inference
process, and testing phase. The drawback of fuzzy approach was the wrong prediction
for boundary values, which was overcomed by adopting decision trees. DT learned from datasets and
predicted the most suitable prioritization technique. Out of 45 test samples, the
framework was able to classify 43 tests accurately.

	Avesani \etal\cite{PAvesani} presented the study that dealt with the scalability
problems which arise in managing the prioritization of a large number of
requirements specified in the the AHP technique. The existing solution to
scalability issues used heuristics. It helped to decide when to stop the pairwise
elicitation process. The proposed framework outperformed AHP by giving an
accurate approximation of the final ranking within a limited elicitation effort. It used rank-based
learning algorithm and produced a ranking of all requirements. This technique
built up the solution by looking at examples. The input for the learning
algorithm were a finite set of requirements, the ranking criteria, initial user
preferences and density function.

	A similar study was performed in \cite{7320432} from the same group
\cite{PAvesani} for identification of decision-making issues related to the
management of risks in Open Source Software adoption in medium and large
organizations. A semi-automated system was proposed that used case based
ranking classification algorithm. The input was priority elicitation of goals by
the decision maker and risk goal ranking function (predefined ranking criteria
ordering the goal). As an output, it ranked the final risk-based goals.

\input{text/analysis_security}

