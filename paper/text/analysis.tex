\subsection{Requirements Specification and Analysis}

\subsubsection{Non-Functional}

Non-functional requirements may not be explicitly mentioned in a formal
specification requirements documents even though, all systems have
them~\cite{Slankas:2013}. Moreover, freeform documents like interview notes,
meeting minutes and scattered requirements specifications include non-functional
requirements which need to be detected and classified. In order to support
analyst in the error-prone task of manually discovering and classifying NFRs
machine learning can be useful. Automatic detection can be used to quickly and
more effectively analyze large and complex documents for searching the
NFRs\cite{Cleland-Huang2007}. This is a classification problem as from a set of
requirements we want to decide a class membership. \\

One of the studies is by Slankas \etal~\cite{Slankas:2013} where they
automatically identified and classified sentences in natural language from use
agreements, install manuals, regulations, request for proposals, requirements
specifications, and user manuals output into 14 different NFRs categories:
Access Control (AC), Audit (AU), Availability (AV), Legal (LG), Look and Feel
(LF), Maintenance (MT), Operational (OP), Privacy (PR), Recoverability (RC),
Performance and Scalability (PS), Reliability (RL), Security (SC), Usability
(US). Their two-step process: 1) parse natural language and turn sentences into
graphs 2) classify sentences into categories with k-nearest neighbor algorithm
led them into finding 20 keywords for each category of NFRs for their
classifier. They trained the NFR classifier with a wide variety of open and
closed source EHRs (Electronic Health Record), various industry standards (HL7,
CCHIT), governmental regulations, and other document sources exist to elicit
documentation.\newline Cleland-Huang \etal~\cite{Cleland-Huang2007} provided the
same approach and used k-nearest neighbor classification for grouping
non-functional requirements: availability, look-and-feel, legal,
maintainability, operational, performance, scalability, security, and usability.
For training their classifier they used 15 requirements specifications developed
as term projects by master students at DePaul University.

\subsubsection{Functional}

Software requirements specifications are usually stated in informal, imprecise
and ambiguous natural language, thus analyzing them is a challenging task.
However, for requirements reuse in Software Product Line analyzing is a vital
task. Automatically extract structured information of functional requirements
from Software Requirements Specifications and grouping them into different
categories is a machine learning classification task\cite{7949577}. \\

Wang \etal~\cite{7949577} applied a combination of machine learning, natural
language processing, and semantic analysis methods for automatically extract functional requirements and classify
them into 10 different cases: Agentive, Action, Objective, Agent mode, Objmod, Locational, Temporal, Manner, Goal,
Constraint. Their framework has four steps: corpus construction,  NLP 
preprocessing, feature extraction and  EFRF (Extended Functional Requirements
Frame) functional cases extraction. which for NLP processing they did
tokenization,   lemmatization, part-of-speech tagging (POS  tagging) and
dependency parsing. They trained their bi-directional LSTM-CRF network which is
a variant of Recurrent Neural Networks(RNN) architecture model with E-commerce
requirements dataset and test it on requirements of automaker systems.
Ultimately, they showed that their trained model on E-commerce requirements
dataset can be used to extract semantic information from the requirements of
automaker systems.

\subsubsection{Functional and Non functional Requirements}

The success of system solely not depends on functional requirements. Just as
functional requirements, it also significantly depends upon the adherence to
non-functional requirements. In general, the primary focus is more for
identification and specification of the FR.  NFRs usually identified and
specified in the late development process that can increase the risks. FRs tend
to be more straightforward e.g. store and retrieve transaction. On the other
side, NFRs are complicated and challenging to implement e.g., making the design
to meet NFRs or design test case for them. Different types of requirements
analyzed in different way and it is useful to have separate division to look at
one particular class. That is why it is necessary to distinguish between FR and
NFR and categorize NFRs into subcategories. This distinction help to manage
changes in requirements. The manual distribution is difficult and time
consuming. Machine learning can be used for reducing the effort and categorizing
the requirements based on the text segment analysis. This is ML classification
task: give the set of requirements and identifying its category. \\

\levi{name of first author here} \etal~\cite{} Automatically classify the user
review text into FR, NFR and others. It further classify the NFR into four
categories as reliability, usability, portability, and performance. It used
supervised machine learning algorithm (bagging) for training the classifier. The
text was trimmed by stop words elimination, lemmatization, stemming, and
sentences split. For augmenting the user review word2vec\levi{add ref} used.
Word2Vec is actually a two layer neural network to process text for finding the
word embedding. \levi{name of first author here} \etal~\cite {Deocadez:2017}
performed semi-supervised classification techniques for automated classification
of FR and NFR in user reviews from the app store. This study deals with two
problems: 1) minimize annotate or label the big dataset of user reviews 2)
classification of FR and NFR. First problem solved by using semi-supervised
self-labeling algorithm. Self-labelling algorithms needs only small amount of
dataset to get the comparable results with supervised techniques. For
classification problem Na√Øve Bayes algorithm used. Features are obtained by
applying standard text mining technique and additional attribute embellishment.
For text mining technique following features used:  Inverse Document Frequency
(IDF)\levi{only introduce acronyms if they are used further ahead in the text}
Transform, Term Frequency (TF) Transform, Lowercase transformation, Minimum term
frequency, Stemmer, Number of words. The second stage involved removing numbers,
2- letter words and other symbolic
characters.\etal~\cite{Kurtanovic:2017} performed automated analysis of number
of software requirements and performed classification on FR, NFR and its different
categories using supervised machine learning algorithm(support vector machine).
Additional dataset of user comments from Amazon used to overcome the data
imbalance problem in NFR. For feature extraction text preprocessing techniques
used such as removal of punctuations, removal of stop words, and lemmatization.

\cite{Deocadez:2017}, \cite{Kurtanovic:2017}, \cite{Guzman:2017},
\cite{Abad:2017}, \cite{Dekhtyar:2017}, \cite{Rashwan:2012}, \cite{Lu:2017},
\cite{Hayes:2014}, \cite{Williams:2017}, \cite{Garzoli:2013},
\cite{Casamayor:2010}, \cite{Wang:2016}, \cite{Hussain:2012}, \cite{Jiang:2014},
\cite{Jha:2017}, \cite{Pinquie:2015}

\input{text/analysis_security}

\subsubsection{Contextual Requirements} 

