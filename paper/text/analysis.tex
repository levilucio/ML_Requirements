\subsection{Requirements Specification and Analysis}

\subsubsection{Non-Functional}

Non-functional requirements may not be explicitly mentioned in a formal
specification requirements documents even though, all systems have
them~\cite{Slankas:2013}. Moreover, freeform documents like interview notes,
meeting minutes and scattered requirements specifications include non-functional
requirements which need to be detected and classified. In order to support
analyst in the error-prone task of manually discovering and classifying NFRs
machine learning can be useful. Automatic detection can be used to quickly and
more effectively analyze large and complex documents for searching the
NFRs\cite{Cleland-Huang2007}. This is a classification problem as from a set of
requirements we want to decide a class membership. \\

One of the studies is by Slankas \etal~\cite{Slankas:2013} where they
automatically identified and classified sentences in natural language from use
agreements, install manuals, regulations, request for proposals, requirements
specifications, and user manuals output into 14 different NFRs categories:
Access Control, Audit, Availability, Legal, Look and Feel, Maintenance, Operational, Privacy, Recoverability,
Performance and Scalability, Reliability, Security, Usability.
Their two-step process:
1) parse natural language and turn sentences into graphs 2) classify sentences into categories with k-nearest neighbor algorithm
led them into finding 20 keywords for each category of NFRs for their
classifier. They trained the NFR classifier with a wide variety of open and
closed source EHRs (Electronic Health Record), various industry standards (HL7,
CCHIT), governmental regulations, and other document sources exist to elicit
documentation.\newline Cleland-Huang \etal~\cite{Cleland-Huang2007} provided the
same approach and used k-nearest neighbor classification for grouping
non-functional requirements: availability, look-and-feel, legal,
maintainability, operational, performance, scalability, security, and usability.
For training their classifier they used 15 requirements specifications developed
as term projects by master students at DePaul University.

\subsubsection{Functional}

Software requirements specifications are usually stated in informal, imprecise and ambiguous natural language, thus analyzing them is a challenging task. However, for requirements reuse analyzing them is a vital task. Automatically extract structured information of functional requirements from Software Requirements Specifications and grouping them into different categories is a machine learning classification task\cite{7949577}. \\ 

Wang \etal~\cite{7949577} applied a combination of machine learning, natural language processing, and semantic analysis methods for automatically extract functional requirements and classify them into 10 different cases: Agentive(The main participant of activities), Action(The main functional operation), Objective(The objects affected by the Action), Agent mode(The modifier or property of the Agentive), Objmod(The modifier or property of the Agentive), Locational(The location or destination of an Action), Temporal(The occurrence time or frequency of an Action), Manner(The way or tool by which an Action is performed), Goal(The purpose to be achieved through the Action), Constraint(The conditions or constraints of the Action). Their framework employed techniques of semantic role labeling and machine learning and has four steps: corpus construction, NLP preprocessing, feature extraction and  EFRF (Extended Functional Requirements Frame) functional cases extraction. which for NLP processing they did tokenization, lemmatization, part-of-speech tagging (POS  tagging) and dependency parsing. They trained their bi-directional LSTM-CRF network which is a variant of Recurrent Neural Networks architecture model with E-commerce requirements dataset and test it on requirements of automaker systems. They proposed EFRF through analyzing the linguistic characterization of SRSs. EFRF consists of 10 mentioned functional cases for capturing the semantic information in the natural language functional requirements. For example, the “Agentive” case can be mapped to “User” or “System” and the “Constraint” is usually corresponding to the “Precondition”. Ultimately, they showed that their trained model on E-commerce requirements dataset can be used to extract semantic information from the requirements of automaker systems.

\subsubsection{Functional and Non functional Requirements}
The success of a system does not solely depend on its functional requirements.
Like functional requirements, it also significantly depends upon the adherence
to non-functional requirements. However, the primary focus is generally more
towards identification and specification of FRs. NFRs are usually identified and
specified in later development stages that can increase the risks in development
life cycle. FRs tend to be more straightforward e.g. store and retrieve
transaction. On the other side, NFRs are complicated and challenging to
implement e.g., making the design to meet NFRs or design test case for them.
Different types of requirements analyzed in a different way, and it is useful to
have a separate division to look at one particular division. That is why it is
necessary to distinguish between FR and NFR and categorize NFRs into
subcategories. This distinction helps to manage changes in requirements. The
manual division is difficult and time consuming. Machine learning can be used
for reducing the effort and categorizing the requirements based on the text
segment analysis. This is ML classification task: give the set of requirements
and identifying its category.\\
Mengmeng Lu \etal~ \cite{Lu:2017} automatically classify the user review text
mobile from application (app) stores  into FR, NFR, and others. It further
classified NFRs into four categories including reliability, usability,
portability, and performance. It used supervised machine learning algorithm
(bagging) for training the classifier. The text trimming used stopwords
elimination, lemmatization, stemming, and sentences split. Word2vec was used for
augmenting the user review, which is a two layer neural network model to process
text for finding the word embedding. Deoxadez
\etal~\cite{Deocadez:2017}performed semi-supervised classification techniques
for automated classification of FRs and NFRs on user reviews from the app store.
This study dealt with two problems: 1) minimize annotation effort or label the
big dataset of user reviews, and 2) classification of FRs and NFRs. The proposed
solution to solve the first problem used semi-supervised self-labeling
algorithm. Self-labeling algorithms required a small amount of dataset to get
comparable results as supervised techniques. Naïve Bayes algorithm was selected
because of high performance results for classification problem. Features were
obtained by applying standard text mining technique and additional attribute
embellishment. For text mining technique, included features were Inverse
Document Frequency (IDF) transform, Term Frequency (TF) transform, lowercase
transformation, minimum term frequency, stemmer, and number of words. The second
stage involved removing numbers, 2- letter words and other symbolic characters.
Kutranvoic \etal ~ \cite {Kurtanovic:2017}performed automated analysis on
software requirements and performed classification on FRs, NFRs and
subcategories of NFRs using supervised machine learning algorithm(support vector
machine). Some NFR had negligble requiremtnst in dataset due to this they were
ignored. The additional dataset of user comments from Amazon was integrated into
the main dataset to avoid the data imbalance problem in NFR. The predictor used
text-preprocessing techniques such as removal of punctuations, removal of stop
words, and lemmatization for feature extraction.All experiments were performed
on dataset given by RE datatrack.
 Abad \etal ~ \cite{Abad:2017} targeted two problems: first is classification of 
 FR and NFR and second classification of NFR into categories. Preprocessing of
 text performed by applying: POS tagging, Entity tagging and temporal tagging
 .Fas a next step feature co-occurrence and regular expression used to increase
 the weight of influential words in the datset. J.48 DT used for the classifying
 the FR and NFR. For achieving second goal topic Modeling unsupervised algorithm
 LDA and BTM applied. For topic generation differnt algorithms such as
 clustering, k-means, hybrid clustering and k-means, BNB were applied.The
 results showed BNB worked better out of clustering, k-means, LDA, BTM.
learnt decision tree to classify the FRs and NFRs and improved results from
~89\% to 95\% by analyzing the requirements in natural language. For NFRs
subclassifcation, Binarized Naïve Bayes (BNB) achieved highest results. The
preprocessing of text involved, Part of Speech (POS) tagging, entity tagging,
and temporal tagging.Garzoli \cite {Garzoli:2013} classified data into five
types: FRs, NFRs, design and construction constraints, operator requirements,
performance requirements.The datset was taken from combat management system of a
Naval Combat System in generall complex system domain. However, the primary goal
was to come up with a general architecture for large-scale and adaptive
requirement analysis. For classification multi VSM model used and for lexical
and grammatical features BoW + N-words + N-POS achieved highest accuracy. 
Wieloch \etal~\cite{Wieloch:2013} introduced methods that enhance the accuracy of tracing (classifying) requirements which occur frequently across multiple projects and/or domains. In the paper, they present Trace by  Classification (TBC),  a machine learning approach in which a classifier is trained to identify and classify requirements and/or other kinds of software artifacts which occur relatively frequently across different projects (they call this process generating trace links for software artifacts in their research). The first step in their approach is preprocessing which is to eliminate common stop words. Then, there is training phase that a set of indicator terms is identified for each NFR category and the classifier will be trained by the set of identified weighted indicator terms that can then be used for the last step which is to classify additional artifacts into functional and non-functional (e.g. look-and-feel, performance, security, etc). A probability value represents the possibility that the new requirement belongs to a certain artifact type is computed as a function of the occurrence of indicator terms of that type in the requirement. 


\cite{Deocadez:2017}, \cite{Kurtanovic:2017}, \cite{Guzman:2017},
\cite{Abad:2017}, \cite{Dekhtyar:2017}, \cite{Rashwan:2012}, \cite{Lu:2017},
\cite{Hayes:2014}, \cite{Williams:2017}, \cite{Garzoli:2013},
\cite{Casamayor:2010}, \cite{Wang:2016}, \cite{Hussain:2012}, \cite{Jiang:2014},
\cite{Jha:2017}, \cite{Pinquie:2015}

\input{text/analysis_security}

\subsubsection{Contextual Requirements} 

