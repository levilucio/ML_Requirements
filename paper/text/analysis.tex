\subsection{Requirements Specification and Analysis}

\subsubsection{Non-Functional}

Non-functional requirements may not be explicitly mentioned in a formal
specification requirements documents even though, all systems have
them~\cite{Slankas:2013}. Moreover, freeform documents like interview notes,
meeting minutes and scattered requirements specifications include non-functional
requirements which need to be detected and classified. In order to support
analyst in the error-prone task of manually discovering and classifying NFRs
machine learning can be useful. Automatic detection can be used to quickly and
more effectively analyze large and complex documents for searching the
NFRs\cite{Cleland-Huang2007}. This is a classification problem as from a set of
requirements we want to decide a class membership. \\

One of the studies is by Slankas \etal~\cite{Slankas:2013} where they
automatically identified and classified sentences in natural language from use
agreements, install manuals, regulations, request for proposals, requirements
specifications, and user manuals output into 14 different NFRs categories:
Access Control (AC), Audit (AU), Availability (AV), Legal (LG), Look and Feel
(LF), Maintenance (MT), Operational (OP), Privacy (PR), Recoverability (RC),
Performance and Scalability (PS), Reliability (RL), Security (SC), Usability
(US). Their two-step process: 1) parse natural language and turn sentences into
graphs 2) classify sentences into categories with k-nearest neighbor algorithm
led them into finding 20 keywords for each category of NFRs for their
classifier. They trained the NFR classifier with a wide variety of open and
closed source EHRs (Electronic Health Record), various industry standards (HL7,
CCHIT), governmental regulations, and other document sources exist to elicit
documentation.\newline Cleland-Huang \etal~\cite{Cleland-Huang2007} provided the
same approach and used k-nearest neighbor classification for grouping
non-functional requirements: availability, look-and-feel, legal,
maintainability, operational, performance, scalability, security, and usability.
For training their classifier they used 15 requirements specifications developed
as term projects by master students at DePaul University.

\subsubsection{Functional}

Software requirements specifications are usually stated in informal, imprecise
and ambiguous natural language, thus analyzing them is a challenging task.
However, for requirements reuse in Software Product Line analyzing is a vital
task. Automatically extract structured information of functional requirements
from Software Requirements Specifications and grouping them into different
categories is a machine learning classification task\cite{7949577}. \\

Wang \etal~\cite{7949577} applied a combination of machine learning, natural
language processing, and semantic analysis methods for automatically extract
non-functional requirements\levi{should non-functional be here?} and classify
them into 10 different cases: Agentive, Action, Objective, Agent mode, Objmod, Locational, Temporal, Manner, Goal,
Constraint. Their framework has four steps: corpus construction,  NLP 
preprocessing, feature extraction and  EFRF (Extended Functional Requirements
Frame) functional cases extraction. which for NLP processing they did
tokenization,   lemmatization, part-of-speech tagging (POS  tagging) and
dependency parsing. They trained their bi-directional LSTM-CRF network which is
a variant of Recurrent Neural Networks(RNN) architecture model with E-commerce
requirements dataset and test it on requirements of automaker systems.
Ultimately, they showed that their trained model on E-commerce requirements
dataset can be used to extract semantic information from the requirements of
automaker systems.

\subsubsection{Functional and Non functional Requirements}
The success of a system does not solely depend on its functional requirements. Like functional requirements, it also significantly depends upon the adherence to non-functional requirements. However, the primary focus is generally more towards identification and specification of FRs. NFRs are usually identified and specified in later development stages that can increase the risks in development life cycle. FRs tend to be more straightforward e.g. store and retrieve transaction. On the other side, NFRs are complicated and challenging to implement e.g., making the design to meet NFRs or design test case for them. Different types of requirements analyzed in a different way, and it is useful to have a separate division to look at one particular division. That is why it is necessary to distinguish between FR and NFR and categorize NFRs into subcategories. This distinction helps to manage changes in requirements. The manual division is difficult and time consuming. Machine learning can be used for reducing the effort and categorizing the requirements based on the text segment analysis. This is ML classification task: give the set of requirements and identifying its category.\\ 
Mengmeng Lu \etal~ \cite{Lu:2017} automatically classify the user review text into FR, NFR, and others. It further classified NFRs into four categories including reliability, usability, portability, and performance. It used supervised machine learning algorithm (bagging) for training the classifier. The text trimming used stopwords elimination, lemmatization, stemming, and sentences split. Word2vec was used for augmenting the user review, which is a two layer neural network model to process text for finding the word embedding. Deoxadez \etal~\cite{Deocadez:2017}performed semi-supervised classification techniques for automated classification of FRs and NFRs in user reviews from the app store. This study dealt with two problems: 1) minimize annotation effort or label the big dataset of user reviews, and 2) classification of FRs and NFRs. The proposed solution to solve the first problem used semi-supervised self-labeling algorithm. Self-labeling algorithms required a small amount of dataset to get comparable results as supervised techniques. Naïve Bayes algorithm was selected because of high performance results for classification problem. Features were obtained by applying standard text mining technique and additional attribute embellishment. For text mining technique, included features were Inverse Document Frequency (IDF) transform, Term Frequency (TF) transform, lowercase transformation, minimum term frequency, stemmer, and number of words. The second stage involved removing numbers, 2- letter words and other symbolic characters. Kutranvoic \etal ~ \cite {Kurtanovic:2017}performed automated analysis on software requirements and performed classification on FRs, NFRs and subcategories of NFRs using supervised machine learning algorithm(support vector machine). The additional dataset of user comments from Amazon was integrated into the main dataset to avoid the data imbalance problem in NFR. The predictor used text-preprocessing techniques such as removal of punctuations, removal of stop words, and lemmatization for feature extraction. Abad                       
\etal ~ \cite{Abad:2017} learnt decision tree to classify the FRs and NFRs and improved results from ~89\% to 95\% by analyzing the requirements in natural language. For NFRs subclassifcation, Binarized Naïve Bayes (BNB) achieved highest results. The preprocessing of text involved, Part of Speech (POS) tagging, entity tagging, and temporal tagging. Garzoli \cite {Garzoli:2013} classified requirements in natural language into five types: FRs, NFRs, design and construction constraints, operator requirements, performance requirements. However, the primary goal was to come up with a general architecture for large-scale and adaptive requirement analysis. They used multi vector space model for this classification.\\



\cite{Deocadez:2017}, \cite{Kurtanovic:2017}, \cite{Guzman:2017},
\cite{Abad:2017}, \cite{Dekhtyar:2017}, \cite{Rashwan:2012}, \cite{Lu:2017},
\cite{Hayes:2014}, \cite{Williams:2017}, \cite{Garzoli:2013},
\cite{Casamayor:2010}, \cite{Wang:2016}, \cite{Hussain:2012}, \cite{Jiang:2014},
\cite{Jha:2017}, \cite{Pinquie:2015}

\subsubsection{Security Requirements} 

Due to the orthogonal character of their impact on a system, \emph{security}
requirements are notoriously difficult to identify, objectify and
quantify~\cite{}. Also during requirement specification, it very often happens
that security requirements are masked by functional requirements (but can be
deduced from the context of the domain the system operates in)~\cite{Riaz:2014}.
Because of this, it often happens in practice that security requirements are
only marginally tackled during system construction~\cite{}, paving the way to
potentially catastrophic consequences.
Machine learning can be of use here by aiding in the identification of segments
of text that describe security requirements. This is a \emph{classification}
problem: given a text, identify which parts of it correspond to which type of
security issues.\\

Jindal\etal~\cite{Jildal:2016} automatically learn decision trees that can be
used to classify security requirements as \emph{authentication}, \emph{access
control}, \emph{encryption} or \emph{data integrity}. The \emph{features} used
are relevant terms found in the text. Such relevant terms are obtained by the
following sequence of actions: 1) removing stop words from the text; 2) stemming
the remaining words; and 3) ranking the stemmed words by their \emph{info-gain}
measure.

Riaz and her colleagues~\cite{Riaz:2014} use the k-nearest neighbors algoritm to
classify sentences in requirements documents as \emph{confidentiality},
\emph{integrity}, \emph{authentication}, \emph{availability},
\emph{accountability} or \emph{privacy} requirements. In order to find adequate
sentences and provide context to the classifier, the authors start by finding a
type for each sentence among the possibilities \emph{title}, \emph{list start},
\emph{list element} or \emph{normal sentence}. For the classification the
authors use a modified version of the Levenshein distance~\cite{} based
on the number of word transformations needed to go from one term in one sentence to a term in
another sentence. The classifier is trained using requirements sentences from
the healthcare domain that are manually classified. A particularity of the
approach is that each security requirement type is associated to a template that
helps in translating the security requirements into functional requirements in
order to ease during the implementation of the final system.


\cite{Knauss:2011} 

\subsubsection{Contextual Requirements} 

