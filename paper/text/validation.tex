\subsection{Requirements Validation}

\subsubsection{Traceability}

Validation is to guarantee that requirements are reflecting stakeholders' needs, confirm the quality of the system, consistency, and traceability. 
 One of the definitions for requirements traceability is given by \cite{Gotel:1994}:
\begin{displayquote} 
“Requirements traceability refers to the ability to describe and follow the life of a requirement, in both a forward and backward direction (i.e., from its origins, through its development and specification, to its subsequent deployment and use, and through periods of on-going refinement and iteration in any of these phases).”
\end{displayquote}
Based on this definition the emphasis is on the ability to track the life of requirements and their established links within other artifacts. However, the main barrier assures traceability is the needed effort for building and maintaining the links between those artifacts. That is why many research has tried to apply machine learning and automated tools for facilitating the establishment of links\cite{Gervasi:2011}. 
Traceability tackled in the research mainly by the use of machine learning classification methods.\\

Wieloch \etal~\cite{Wieloch:2013} introduced the hurdle of traceability methods that enhance the accuracy of tracing requirements which occur frequently across multiple projects and/or domains. In the paper, they present Trace by  Classification (TBC),  a machine learning approach in which a classifier is trained to generate trace links for requirements and/or other kinds of software artifacts which occur relatively frequently across different projects. The first step in their approach is preprocessing which is to eliminate common stop words. Then, there is training phase that a set of indicator terms is identified for each NFR category and the classifier will be trained by the set of identified weighted indicator terms that can then be used for the last step which is to classify target documents into specific types.\newline

Gervasi \etal~\cite{Gervasi:2011} investigate what can be learned from links that are already established. They build classifiers as a mean to develop models of tracing that can then be interpreted by humans to understand how requirement tracing is done in practice. Their purpose is to revise the existing models of hard-coded traceability tools such as VSM. 
They used a publicly-available dataset of requirements with traceability information, originally based on the CM-1 project by the NASA Metrics Data Program. Their approach has 5 steps: 1) tokenize and stem requirements and removing stopwords 2) derive two features from each term t in the vocabulary, one for the occurrence of t in a high-level requirement and one for the similar occurrence in a low-level requirement 3) transfer requirements into a vector of features 4) derive set of classification cases 5) finally,  use the dataset to train and test two different classifiers from the WEKA collection, a Naive Bayesian classifier and the J48 decision-tree classifier.\newline

Sultanov \etal~\cite{Sultanov:2013} finds traceability candidates from high-level to low-level requirements by the use of reinforcement learning. They used textual high and low-level requirements documents as an input and try to find the candidate traces. Their technique demonstrated statistically significantly better results than the Information Retrieval technique. 





