\section{Discussion}
\label{sec:discussion}

Our survey work implicitly points to a number of trends that we will
concretize and summarize in this section. Note that while the pointers we
provide here are informed by the literature review we conducted, this survey is
not fully systematic (as described in section~\ref{sec:threats_to_validity}) which
means our conclusions may be revised and/or extended by future surveys of the
domain.

Table \ref{tab:summary} summarizes our findings. It provides partial answers to
\textbf{RQ2} (``What types of learning methods are used when \ML is applied to
\RE?'') and \textbf{RQ3} (``Which are the \RE problems that are currently using
\ML methods?'') in columns \emph{ML Task} and  \emph{themes}, respectively.
The table also provides partial responses to \textbf{RQ1} (``What is the current
state of the practice in \ML${\&}$\RE?") and \textbf{RQ4} (``Is using \ML
methods improving \RE?''). The answer to \textbf{RQ1} seems to be ``at its
beginning'', given the prevalent lack of comparison with the state of the art
as can be observed in \tab{tab:summary}. The answer to \textbf{RQ4} is
``unknown'', given that most of the studies read by us were initial proposals
with little academic or industrial validation in real software engineering tools or projects.

Note that \tab{tab:summary} provides additional information on which types of
algorithms are used for each kind of theme, as well as datasets used for
learning and which are available online.

It is obvious from our survey that \NLP techniques are heavily used
throughout a majority of the research tacking the application of \ML to
\RE. This is not surprising and even intuitive. \RE is the area of software
engineering where natural language is employed more ubiquitously, as \RE
techniques and tools play the role of interface between stakeholders such as
clients, certification entities, architects or developers. Although many
attempts have been done to bring formality to requirements
engineering~\cite{Teufl17,LucioRCA16}, the \emph{de facto} language between
technical and non-technical stakeholders for real-world projects continues being
natural language, and in particular English.
The IBM Rational \DOORS family~\cite{doors} of tools is an example
of a natural-language based tool for requirement engineering that has become the
reference in many domains. In the techniques we have observed, \NLP is heavily
used for the preprocessing stages of natural language in order to bring the data to a format
that can be consumed by a learning algorithm (see
section~\ref{sec:preprocessing}).
 
The authors of the articles we have processed in our survey of point
to the idea that \ML can potentially bring about enormous benefits in terms of
processing and taking decisions based on  large amounts of imprecise and
ambiguous data\levi{some citations here}. In the real-world of software
engineering, parsing and summarizing requirements is a very time-consuming
activity. Also, decisions taken by technical stakeholders are often based on imprecise,
incomplete and noisy information and are supported by rules-of-thumb, experience
and intuition. \ML is by nature built to handle and cope with such challenges
-- it based on data and it's main purpose is exactly to build model of patterns
that humans associate to rules-of-thumb, experience or intuitions. Additionally,
\ML methods often provide a precise degree of certainty regarding the
correctness of decisions taking during a software engineering project. Such
measures, although valid regarding the quality of the learning process, allow
assessing the risk associated to certain steps in the course of a project.

In the sequence of the previous paragraph, a large set of datasets
on \RE are available online. We have identified a few of such datasets in
\tab{summary}. This fact is a cornerstone for the domain, as most \ML
algorithms existing nowadays are vey data-intensive. One of the authors of this
survey has recently written a similar article on the application of \ML to
formal verification~\cite{AmLuBi:2018}, for which the datasets available
to learn from are typically very small and almost never made public. The authors
of the article recognize that such scarceness of data is partly due to the niche
nature of the domain of formal verification, where the datasets are mostly in
the form of mathematical proofs. Nonetheless, and in spite of the large body of
work regarding the application of \ML to formal verification, such scarceness of
data poses a problem not only to the automated learning, but also to the
scientific validation of such proposals. This is not the case in \RE, where many
datasets are publicly available on which both learning and validation can be
done.

The majority of the articles we found on the topic of \ML and \RE have to do
with either the \emph{elicitation} or the \emph{analysis} phases of \RE. These
findings are compatible with the idea that parsing requirements texts and
classifying the information that is contained in them is strenuous for humans
and thus it is desirable that such tasks are as automatic as possible. The
\emph{validation} and \emph{management} phases in \RE also imply tasks that can
be automated as we have shown through our survey, but the state of the art in
the domain seems to imply that the first two phases have priority for
researchers and practicioners.

Also, we have observed through our readings that while \emph{classification} is
the most used \ML task, \emph{clustering} also plays an important role in the
domain of \ML applied to \RE. This contradicts the results
in~\cite{AmLuBi:2018}, where \emph{clustering} has almost no expression in work
that applied \ML to formal verification. We believe this provides support to the
thesis that \ML is particularly appropriate to \RE -- given \emph{clustering} is
especially useful when mining non-formal data such as free-form text.

\input{text/SummaryTable}

\levi{internal vs external}